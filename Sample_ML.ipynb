{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "_j9woMPgy5Rh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import typing\n",
        "import csv\n",
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoNr5s0b106n",
        "outputId": "7e7cc4da-0331-4865-e4f8-340bfd0325a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "5eTJpw8izA8a"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, numin, numout):\n",
        "        super(Net, self).__init__()\n",
        "        fc = []\n",
        "        fc.append(nn.Linear(numin, numout))\n",
        "        for i in range(20):\n",
        "            fc.append(nn.Linear(numout, numout))\n",
        "        self.fc = nn.ModuleList(fc)\n",
        "        #self.relu = nn.ReLU()\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        for fc in self.fc:\n",
        "            x = fc(x)\n",
        "            #x = self.relu(x)\n",
        "            x = self.sig(x) \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2gWIQAc307M",
        "outputId": "8758b6d7-7a1a-4b7c-bacf-6a1b86774120"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "350 50\n",
            "50 50\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    with open('input.csv', 'r', encoding='shift-jis') as f:\n",
        "        reader = csv.reader(f)\n",
        "        next(reader)  # skip the header\n",
        "        inputs = []\n",
        "        for row in reader:\n",
        "            v = []\n",
        "            for i in range(1, len(row)):\n",
        "                v.append(float(row[i]))\n",
        "            inputs.append(v)\n",
        "  \n",
        "        train_input = []\n",
        "        for i in range(len(inputs[0])-50):\n",
        "          each_data=[]\n",
        "          for k in range(50):\n",
        "            each_data.append(inputs[k][i])\n",
        "          train_input.append(each_data)\n",
        "        print(len(train_input), len(train_input[0]))\n",
        "\n",
        "        test_input = []\n",
        "        for i in range(len(inputs[0])-50, len(inputs[0])):\n",
        "          each_data = []\n",
        "          for k in range(50):\n",
        "            each_data.append(inputs[k][i])\n",
        "          test_input.append(each_data)\n",
        "        print(len(test_input), len(test_input[0]))\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWf6W9mY4V8f",
        "outputId": "20c40223-9e40-49f0-ccee-0b95daa03da5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "350 50\n",
            "50 50\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    with open('target.csv', 'r',\n",
        "              encoding='shift-jis') as f:\n",
        "        reader = csv.reader(f)\n",
        "        next(reader)  # skip the header\n",
        "        targets = []\n",
        "        for row in reader:\n",
        "            v = []\n",
        "            for i in range(1, len(row)):\n",
        "                v.append(float(row[i]))\n",
        "            targets.append(v)\n",
        "        \n",
        "        train_target = []\n",
        "        for i in range(350):\n",
        "          each_data=[]\n",
        "          for k in range(50):\n",
        "            each_data.append(targets[k][i])\n",
        "          train_target.append(each_data)\n",
        "        print(len(train_target), len(train_target[0]))\n",
        "\n",
        "        test_target = []\n",
        "        for i in range(350, 400):\n",
        "          each_data = []\n",
        "          for k in range(50):\n",
        "            each_data.append(targets[k][i])\n",
        "          test_target.append(each_data)\n",
        "        print(len(test_target), len(test_target[0]))\n",
        "except FileNotFoundError as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "cCAwcnA-QVw9"
      },
      "outputs": [],
      "source": [
        "train_input = preprocessing.normalize(np.array(train_input)).astype(float)\n",
        "train_target = preprocessing.normalize(np.array(train_target)).astype(float)\n",
        "\n",
        "test_input = preprocessing.normalize(np.array(test_input)).astype(float)\n",
        "test_target = preprocessing.normalize(np.array(test_target)).astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knmbrjwGeS_V",
        "outputId": "cd5a8b45-6ad1-4f11-b957-d7db5054a3a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The loss for epoch 1:  0.2427482157945633\n",
            "The loss for epoch 2:  0.17684519290924072\n",
            "The loss for epoch 3:  0.12230417132377625\n",
            "The loss for epoch 4:  0.07860908657312393\n",
            "The loss for epoch 5:  0.046516090631484985\n",
            "The loss for epoch 6:  0.025612695142626762\n",
            "The loss for epoch 7:  0.013590361922979355\n",
            "The loss for epoch 8:  0.007324795238673687\n",
            "The loss for epoch 9:  0.004232653882354498\n",
            "The loss for epoch 10:  0.0027234877925366163\n",
            "The loss for epoch 11:  0.0019728976767510176\n",
            "The loss for epoch 12:  0.0015866004396229982\n",
            "The loss for epoch 13:  0.0013797247083857656\n",
            "The loss for epoch 14:  0.0012643940281122923\n",
            "The loss for epoch 15:  0.0011975928209722042\n",
            "The loss for epoch 16:  0.0011575089301913977\n",
            "The loss for epoch 17:  0.001132671139203012\n",
            "The loss for epoch 18:  0.0011168277123942971\n",
            "The loss for epoch 19:  0.0011064549908041954\n",
            "The loss for epoch 20:  0.0010995041811838746\n",
            "The loss for epoch 21:  0.0010947487317025661\n",
            "The loss for epoch 22:  0.001091433921828866\n",
            "The loss for epoch 23:  0.001089085009880364\n",
            "The loss for epoch 24:  0.0010873958235606551\n",
            "The loss for epoch 25:  0.0010861646151170135\n",
            "The loss for epoch 26:  0.0010852570412680507\n",
            "The loss for epoch 27:  0.0010845804354175925\n",
            "The loss for epoch 28:  0.0010840719332918525\n",
            "The loss for epoch 29:  0.0010836859000846744\n",
            "The loss for epoch 30:  0.0010833910200744867\n",
            "The loss for epoch 31:  0.001083164126612246\n",
            "The loss for epoch 32:  0.001082988572306931\n",
            "The loss for epoch 33:  0.0010828519007191062\n",
            "The loss for epoch 34:  0.001082745147868991\n",
            "The loss for epoch 35:  0.0010826613288372755\n",
            "The loss for epoch 36:  0.0010825953213497996\n",
            "The loss for epoch 37:  0.0010825430508702993\n",
            "The loss for epoch 38:  0.0010825014906004071\n",
            "The loss for epoch 39:  0.0010824687778949738\n",
            "The loss for epoch 40:  0.0010824424680322409\n",
            "The loss for epoch 41:  0.0010824213968589902\n",
            "The loss for epoch 42:  0.0010824046330526471\n",
            "The loss for epoch 43:  0.001082391245290637\n",
            "The loss for epoch 44:  0.0010823803022503853\n",
            "The loss for epoch 45:  0.0010823715711012483\n",
            "The loss for epoch 46:  0.0010823644697666168\n",
            "The loss for epoch 47:  0.0010823586490005255\n",
            "The loss for epoch 48:  0.0010823539923876524\n",
            "The loss for epoch 49:  0.0010823500342667103\n",
            "The loss for epoch 50:  0.0010823467746376991\n",
            "The loss for epoch 51:  0.001082344213500619\n",
            "The loss for epoch 52:  0.0010823418851941824\n",
            "The loss for epoch 53:  0.0010823397897183895\n",
            "The loss for epoch 54:  0.0010823383927345276\n",
            "The loss for epoch 55:  0.001082336762920022\n",
            "The loss for epoch 56:  0.001082335482351482\n",
            "The loss for epoch 57:  0.0010823342017829418\n",
            "The loss for epoch 58:  0.0010823331540450454\n",
            "The loss for epoch 59:  0.0010823322227224708\n",
            "The loss for epoch 60:  0.0010823310585692525\n",
            "The loss for epoch 61:  0.0010823302436619997\n",
            "The loss for epoch 62:  0.0010823291959241033\n",
            "The loss for epoch 63:  0.0010823284974321723\n",
            "The loss for epoch 64:  0.0010823275661095977\n",
            "The loss for epoch 65:  0.001082326634787023\n",
            "The loss for epoch 66:  0.0010823254706338048\n",
            "The loss for epoch 67:  0.001082324655726552\n",
            "The loss for epoch 68:  0.001082323957234621\n",
            "The loss for epoch 69:  0.0010823230259120464\n",
            "The loss for epoch 70:  0.00108232197817415\n",
            "The loss for epoch 71:  0.0010823210468515754\n",
            "The loss for epoch 72:  0.0010823202319443226\n",
            "The loss for epoch 73:  0.0010823191842064261\n",
            "The loss for epoch 74:  0.0010823182528838515\n",
            "The loss for epoch 75:  0.001082317205145955\n",
            "The loss for epoch 76:  0.0010823161574080586\n",
            "The loss for epoch 77:  0.001082315226085484\n",
            "The loss for epoch 78:  0.0010823141783475876\n",
            "The loss for epoch 79:  0.0010823131306096911\n",
            "The loss for epoch 80:  0.0010823119664564729\n",
            "The loss for epoch 81:  0.0010823110351338983\n",
            "The loss for epoch 82:  0.0010823099873960018\n",
            "The loss for epoch 83:  0.0010823088232427835\n",
            "The loss for epoch 84:  0.001082307775504887\n",
            "The loss for epoch 85:  0.0010823067277669907\n",
            "The loss for epoch 86:  0.0010823054471984506\n",
            "The loss for epoch 87:  0.0010823042830452323\n",
            "The loss for epoch 88:  0.0010823032353073359\n",
            "The loss for epoch 89:  0.0010823019547387958\n",
            "The loss for epoch 90:  0.0010823009070008993\n",
            "The loss for epoch 91:  0.0010822998592630029\n",
            "The loss for epoch 92:  0.001082298462279141\n",
            "The loss for epoch 93:  0.0010822974145412445\n",
            "The loss for epoch 94:  0.0010822962503880262\n",
            "The loss for epoch 95:  0.0010822949698194861\n",
            "The loss for epoch 96:  0.0010822938056662679\n",
            "The loss for epoch 97:  0.0010822925250977278\n",
            "The loss for epoch 98:  0.0010822913609445095\n",
            "The loss for epoch 99:  0.0010822901967912912\n",
            "The loss for epoch 100:  0.0010822889162227511\n"
          ]
        }
      ],
      "source": [
        "numInput = 50\n",
        "numOutput = 50\n",
        "model = Net(numInput, numOutput)\n",
        "\n",
        "trainInputs = torch.tensor(train_input)\n",
        "trainTargets = torch.tensor(train_target)\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_list = []\n",
        "\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    trainOutputs = model(trainInputs.float())\n",
        "    loss = criterion(trainOutputs, trainTargets.float())\n",
        "    loss_list.append(loss)\n",
        "    print(\"The loss for epoch \"+str(epoch+1)+\": \",loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "m_BBObbYYO_c",
        "outputId": "50e24475-59ee-43d0-89bd-248a94780e96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7cea2ba990>]"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXZ0lEQVR4nO3de3Dd5X3n8fdHOrpalmUsBeML2CROwL3hRHWyzZa2KaGm7eDsDBnMbmfJlA7TNkzbze7s0EkndOnOTtLubJu2TApDaNNOE5qQttFkSCjhsu3sLonlhAK2IRgTQMbGwndjS9blu3+cn+TjE9k6to58xPN8XhONzu+m8/3Nj3zOz8/vOc+jiMDMzNLV1OgCzMxsfjnozcwS56A3M0ucg97MLHEOejOzxJUaXUC13t7eWLNmTaPLMDN7W9m2bdubEdE307aagl7SJuCzQDNwf0R8umr7J4BfA8aBYeBXI+KVYtsE8Gyx66sRceO53mvNmjUMDg7WUpaZmRUkvXK2bbMGvaRm4B7gw8AQsFXSQETsqNjte0B/RJyQ9BvAHwI3F9tORsQ1F1y9mZnNSS1t9BuBXRGxOyJOAQ8Cmyt3iIgnIuJEsfgUsKq+ZZqZ2YWqJehXAq9VLA8V687mNuAbFcvtkgYlPSXpIzMdIOn2Yp/B4eHhGkoyM7Na1fVhrKRfAfqBn6lYfUVE7JF0JfC4pGcj4qXK4yLiPuA+gP7+fo/JYGZWR7Xc0e8BVlcsryrWnUHSdcAngRsjYnRqfUTsKX7vBp4ENsyhXjMzO0+1BP1WYJ2ktZJagS3AQOUOkjYA91IO+f0V65dKaite9wIfBCof4pqZ2TybtekmIsYl3QE8Qrl75QMRsV3S3cBgRAwAfwR0AV+RBKe7UV4N3CtpkvKHyqereuuYmdk800Ibpri/vz8upB/9sZEx7v+Xl/m5q97BNat75qEyM7OFS9K2iOifaVsyQyCMTwSffexFvvvKoUaXYma2oCQT9F3t5VaoYyPjDa7EzGxhSSboW5qbaG9p4vjoWKNLMTNbUJIJeoDF7S2+ozczq5JY0Jc4NuqgNzOrlFbQt5V8R29mViWtoG9v4diI2+jNzColFfRdbSWO+47ezOwMSQX94nY33ZiZVUss6N10Y2ZWLamg72ov8dapCSYmF9awDmZmjZRU0HcX34497i6WZmbTkgr6rjYHvZlZtaSCfnF7C4Db6c3MKiQW9B7YzMysWlJBPzWCpfvSm5mdllTQTz2MPeqmGzOzaUkFfVdbuY3eD2PNzE5LKujdRm9m9sOSCvrO1maa5F43ZmaVkgp6SR7YzMysSlJBD55lysysWoJB71mmzMwqpRn0bqM3M5uWYNC76cbMrFJyQd/VVnI/ejOzCskFvWeZMjM7U3JB39Xu7pVmZpWSC/ru9hZOTUwyMjbR6FLMzBaE5ILewyCYmZ0puaD3LFNmZmdKLug9y5SZ2ZlqCnpJmyS9IGmXpDtn2P4JSTskPSPpMUlXVGy7VdKLxc+t9Sx+JtN39G66MTMDagh6Sc3APcANwHrgFknrq3b7HtAfET8OPAT8YXHsJcBdwPuBjcBdkpbWr/wftnh68hEHvZkZ1HZHvxHYFRG7I+IU8CCwuXKHiHgiIk4Ui08Bq4rXvwA8GhEHI+IQ8CiwqT6lz6zbTTdmZmeoJehXAq9VLA8V687mNuAb53OspNslDUoaHB4erqGks5ueN9YPY83MgDo/jJX0K0A/8Efnc1xE3BcR/RHR39fXN6captro3b3SzKyslqDfA6yuWF5VrDuDpOuATwI3RsTo+RxbT62lJtpKTb6jNzMr1BL0W4F1ktZKagW2AAOVO0jaANxLOeT3V2x6BLhe0tLiIez1xbp5VR7B0m30ZmYApdl2iIhxSXdQDuhm4IGI2C7pbmAwIgYoN9V0AV+RBPBqRNwYEQcl/QHlDwuAuyPi4LycSYXu9pJ73ZiZFWYNeoCIeBh4uGrdpypeX3eOYx8AHrjQAi+EBzYzMzstuW/GgmeZMjOrlGTQe/IRM7PTkgx6TydoZnZaokHvWabMzKakGfRF083kZDS6FDOzhksz6Ivxbo6f8l29mVmSQT893o2bb8zM0gx6TydoZnZaokHvoYrNzKYkGfTTI1i6L72ZWZpB3+2mGzOzaUkGvR/GmpmdlmTQu43ezOy0JIN+UWszzU3iqIPezCzNoJdEd3uJIycd9GZmSQY9QE9nK4dPOOjNzJIN+iUdLb6jNzPDQW9mlrxkg76ns8VNN2ZmpBz0HS0cPnGq0WWYmTVcskG/pKOFY6PjTHhMejPLXLpB39lKhL80ZWaWbND3dJS/Het2ejPLXbJBv6QIeve8MbPcJRv0PZ3FHb2D3swyl3zQ+47ezHKXbNB3TzXduIulmWUu2aBf4oexZmZAwkHfVmqms7XZTTdmlr1kgx7Kd/V+GGtmuUs/6N10Y2aZSzroezpbOOo7ejPLXE1BL2mTpBck7ZJ05wzbr5X0XUnjkm6q2jYh6eniZ6Behdei3HTjXjdmlrfSbDtIagbuAT4MDAFbJQ1ExI6K3V4FPgb8lxn+xMmIuKYOtZ63no5WDp843Ii3NjNbMGYNemAjsCsidgNIehDYDEwHfUT8oNg2OQ81XrCeTk8+YmZWS9PNSuC1iuWhYl2t2iUNSnpK0kdm2kHS7cU+g8PDw+fxp8+tu6OF0fFJRsYm6vY3zczebi7Gw9grIqIf+PfAn0h6Z/UOEXFfRPRHRH9fX1/d3nh6vBv3vDGzjNUS9HuA1RXLq4p1NYmIPcXv3cCTwIbzqG9OejpaAY93Y2Z5qyXotwLrJK2V1ApsAWrqPSNpqaS24nUv8EEq2vbn2+lhENzzxszyNWvQR8Q4cAfwCLAT+HJEbJd0t6QbAST9pKQh4KPAvZK2F4dfDQxK+lfgCeDTVb115pVHsDQzq63XDRHxMPBw1bpPVbzeSrlJp/q4/wv82BxrvGDTd/QOejPLWNLfjF0ydUfvh7FmlrGkg35xW4nmJrnpxsyylnTQS6K7veRhEMwsa0kHPUBPZ6v70ZtZ1pIP+iUdHgbBzPLmoDczS1zyQd/T6clHzCxv6Qe97+jNLHPJB/2SjhaOjowxMRmNLsXMrCHSD/rOViLg2Ijv6s0sT8kHfU+Hx7sxs7wlH/SnR7B00JtZnpIP+unJR3xHb2aZyibo3XRjZrlKPui7p9roPfmImWUq+aBf4oexZpa55IO+rdRMZ2szh/ww1swylXzQAyztbOXQW266MbM8ZRH0vV2tvOmgN7NMZRH0y7raOHB8tNFlmJk1RB5Bv6iVA8d9R29mecoj6LvaOPDWKBEe2MzM8pNF0Pd2tTI2ERwdGW90KWZmF10mQd8G4HZ6M8tSFkG/rKsVgAPueWNmGcoj6Bf5jt7M8pVF0PcWd/RvuueNmWUoi6BfuqhounHQm1mGsgj6luYmejpbOPCWm27MLD9ZBD34S1Nmlq98gr6rjTf9MNbMMpRN0Pd2tbp7pZllqaagl7RJ0guSdkm6c4bt10r6rqRxSTdVbbtV0ovFz631Kvx8LVvkgc3MLE+zBr2kZuAe4AZgPXCLpPVVu70KfAz4YtWxlwB3Ae8HNgJ3SVo697LP37KuVg6dGGN8YrIRb29m1jC13NFvBHZFxO6IOAU8CGyu3CEifhARzwDVKfoLwKMRcTAiDgGPApvqUPd5W1YMg3DQc8eaWWZqCfqVwGsVy0PFulrUdKyk2yUNShocHh6u8U+fn173pTezTC2Ih7ERcV9E9EdEf19f37y8x7Lpgc0c9GaWl1qCfg+wumJ5VbGuFnM5tq5OD2zmB7Jmlpdagn4rsE7SWkmtwBZgoMa//whwvaSlxUPY64t1F11vMbCZx7sxs9zMGvQRMQ7cQTmgdwJfjojtku6WdCOApJ+UNAR8FLhX0vbi2IPAH1D+sNgK3F2su+i6O0qUmuQulmaWnVItO0XEw8DDVes+VfF6K+VmmZmOfQB4YA411oUklnV5GAQzy8+CeBh7sSxb1OY2ejPLTl5B39XqNnozy05WQd/b5Tt6M8tPVkHvoYrNLEd5BX1XGydOTXDi1HijSzEzu2gyC3oPg2Bm+ckq6Hunvx3roDezfGQV9MsWTY134weyZpaPvILeTTdmlqG8gn5qvBt3sTSzjGQV9B2tzSxqbfYdvZllJaugh3IXy+FjvqM3s3xkF/SXLWln75GTjS7DzOyiyS7oV/Z08PrhkUaXYWZ20WQX9Ct6Oth3dITxiep5zM3M0pRl0E9MBvvdTm9mmcgw6NsBeP2w2+nNLA/ZBf3Kng4A9jjozSwT2QX9ZUXQ+4GsmeUiu6DvaiuxpKPFTTdmlo3sgh7KD2Qd9GaWiyyDfmVPu9vozSwbWQb9ip4O9h5xG72Z5SHboD9ycozjo55S0MzSl23QA+x1842ZZSDLoF9ZfGnK7fRmloMsg36F+9KbWUayDPp3LG6nuUnuYmlmWcgy6JubxPLudge9mWUhy6CH8pg3bqM3sxxkG/Qretp53TNNmVkGMg76DvYdGWFiMhpdipnZvKop6CVtkvSCpF2S7pxhe5ukvyu2f1vSmmL9GkknJT1d/PxFfcu/cCt6OhibCN487glIzCxtpdl2kNQM3AN8GBgCtkoaiIgdFbvdBhyKiHdJ2gJ8Bri52PZSRFxT57rnrHJc+ku72xtcjZnZ/Knljn4jsCsidkfEKeBBYHPVPpuBLxSvHwJ+XpLqV2b9ne5L73Z6M0tbLUG/EnitYnmoWDfjPhExDhwBlhXb1kr6nqT/LemnZ3oDSbdLGpQ0ODw8fF4ncKE8paCZ5WK+H8buBS6PiA3AJ4AvSuqu3iki7ouI/ojo7+vrm+eSyha3t7C4veRvx5pZ8moJ+j3A6orlVcW6GfeRVAKWAAciYjQiDgBExDbgJeDdcy26Xlb2dDB06ESjyzAzm1e1BP1WYJ2ktZJagS3AQNU+A8CtxeubgMcjIiT1FQ9zkXQlsA7YXZ/S5+6dfV28uP94o8swM5tXswZ90eZ+B/AIsBP4ckRsl3S3pBuL3T4PLJO0i3ITzVQXzGuBZyQ9Tfkh7a9HxMF6n8SFumr5Yl45cIK3PC69mSVs1u6VABHxMPBw1bpPVbweAT46w3FfBb46xxrnzVWXlR8XvPDGMd57+dIGV2NmNj+y/WYslO/oAZ7fe6zBlZiZzZ+sg37V0g662ko8v+9oo0sxM5s3WQe9JK5avth39GaWtKyDHuCqyxazc99RIjy4mZmlyUG/vJtjI+O8fsRfnDKzNGUf9FdfNvVA1u30Zpam7IP+3ZcWQb/P7fRmlqbsg35xewurL+lgp+/ozSxR2Qc9lNvpfUdvZqly0ANXL1/M7uHjjIxNNLoUM7O6c9BTHgphMmCXBzgzswQ56Dk9FMIOt9ObWYIc9MAVyxbR3tLkb8iaWZIc9EBzk3jPpYvZsfdIo0sxM6s7B33h/VcuY9srhzg2MtboUszM6spBX7h+/aWMTQRPvnBxJic3M7tYHPSFDZcvpberlX/a8UajSzEzqysHfaG5SVx39aU88fx+Rsfdn97M0uGgr3D9j1zK8dFxntq9YKa1NTObMwd9hZ96Zy+drc380/Z9jS7FzKxuHPQV2lua+dn39PHojjeYnPREJGaWBgd9levXL2f/sVH+dehwo0sxM6sLB32Vn3vPOyg1yb1vzCwZDvoqSzpb+MCVyxh4+nX3vjGzJDjoZ3D7tVey5/BJ7v+XlxtdipnZnDnoZ3Dtu/u44UeX82ePv8jQoRONLsfMbE4c9Gfxe7+8HiH++9d3NroUM7M5cdCfxcqeDu740Lv45vZ9PPnC/kaXY2Z2wRz05/BrP72WK3sX8cl/eI7dw559yszenhz059BWauaPb76Gk2MTbL7n//DP3/fIlmb29uOgn8VPrO7hax//ICt7OvjYX36Hzz35EidPudulmb19OOhrsPqSTr76Gz/F9euX85lvPs/G//Et7vraczy35wgTHirBzBY4RcweVJI2AZ8FmoH7I+LTVdvbgL8G3gccAG6OiB8U234XuA2YAH4rIh4513v19/fH4ODg+Z/JRRARfOflg3zxO6/yjWf3cWpiks7WZn5kRTfrL+tmRU8Hy5e007e4je72FrraSixqK9HR2kxbqYlSk5DU6NMwswRJ2hYR/TNumy3oJTUD3wc+DAwBW4FbImJHxT6/Cfx4RPy6pC3Av4uImyWtB74EbARWAN8C3h0RZ237WMhBX+ngW6d4/Pn9PLfnCM/uOcLze4/y1ixNOk2CUnM58JunfiSamkSToEmiqfggkIofVPymWH/6g+KMjwzN+PIMC+VDZmFUYbbwXHVZN392y4YLOvZcQV+q4fiNwK6I2F38sQeBzcCOin02A79fvH4I+HOVU2Uz8GBEjAIvS9pV/L3/dyEnspBcsqiVm963ipvet2p63fHRcd44OsL+o6McGxnj+Og4x0fHGR2bZHR8gtHxScYmgonJ8u/JCCYmy78nJyEIJorfxf+ICKY+iis/kys/nis/rM/6sb1AWphioRRitgCtXtoxL3+3lqBfCbxWsTwEvP9s+0TEuKQjwLJi/VNVx66sfgNJtwO3A1x++eW11r7gdLWV6Orr4p19XY0uxcxs2oJ4GBsR90VEf0T09/X1NbocM7Ok1BL0e4DVFcurinUz7iOpBCyh/FC2lmPNzGwe1RL0W4F1ktZKagW2AANV+wwAtxavbwIej3LD8QCwRVKbpLXAOuA79SndzMxqMWsbfdHmfgfwCOXulQ9ExHZJdwODETEAfB74m+Jh60HKHwYU+32Z8oPbceDj5+pxY2Zm9VdTP/qL6e3SvdLMbCE5V/fKBfEw1szM5o+D3swscQ56M7PELbg2eknDwCtz+BO9wJt1KuftIsdzhjzPO8dzhjzP+3zP+YqImPGLSAsu6OdK0uDZHkikKsdzhjzPO8dzhjzPu57n7KYbM7PEOejNzBKXYtDf1+gCGiDHc4Y8zzvHc4Y8z7tu55xcG72ZmZ0pxTt6MzOr4KA3M0tcMkEvaZOkFyTtknRno+uZL5JWS3pC0g5J2yX9drH+EkmPSnqx+L200bXWm6RmSd+T9PViea2kbxfX/O+K0VWTIqlH0kOSnpe0U9K/Sf1aS/pPxX/bz0n6kqT2FK+1pAck7Zf0XMW6Ga+tyv60OP9nJL33fN4riaAv5rW9B7gBWA/cUsxXm6Jx4D9HxHrgA8DHi3O9E3gsItYBjxXLqfltYGfF8meAP46IdwGHKE9Cn5rPAt+MiKuAn6B8/slea0krgd8C+iPiRymPmLuFNK/1XwGbqtad7dreQHmY93WUZ+P73Pm8URJBT8W8thFxCpia1zY5EbE3Ir5bvD5G+f/4Kymf7xeK3b4AfKQxFc4PSauAXwLuL5YFfIjyHMWQ5jkvAa6lPAw4EXEqIg6T+LWmPHx6RzGJUSewlwSvdUT8M+Vh3Sud7dpuBv46yp4CeiRdVut7pRL0M81r+0Nz06ZG0hpgA/Bt4NKI2Fts2gdc2qCy5sufAP8VmCyWlwGHI2K8WE7xmq8FhoG/LJqs7pe0iISvdUTsAf4n8CrlgD8CbCP9az3lbNd2ThmXStBnR1IX8FXgdyLiaOW2YnavZPrNSvplYH9EbGt0LRdZCXgv8LmI2AC8RVUzTYLXeinlu9e1wApgET/cvJGFel7bVII+q7lpJbVQDvm/jYi/L1a/MfVPueL3/kbVNw8+CNwo6QeUm+U+RLntuqf45z2kec2HgKGI+Hax/BDl4E/5Wl8HvBwRwxExBvw95euf+rWecrZrO6eMSyXoa5nXNglF2/TngZ0R8b8qNlXO23sr8LWLXdt8iYjfjYhVEbGG8rV9PCL+A/AE5TmKIbFzBoiIfcBrkt5TrPp5ytNyJnutKTfZfEBSZ/Hf+tQ5J32tK5zt2g4A/7HoffMB4EhFE8/sIiKJH+AXge8DLwGfbHQ983ie/5byP+eeAZ4ufn6Rcpv1Y8CLwLeASxpd6zyd/88CXy9eX0l5svldwFeAtkbXNw/new0wWFzvfwSWpn6tgf8GPA88B/wN0JbitQa+RPk5xBjlf73ddrZrC4hyz8KXgGcp90qq+b08BIKZWeJSaboxM7OzcNCbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mlrj/D+t4foKXIo3TAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "losses = []\n",
        "for loss in loss_list:\n",
        "  losses.append(loss.item())\n",
        "plt.plot(range(100), losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "tmmckaXBAj81"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/Machine_Learning_sample/NetModel2.pth\" \n",
        "torch.save(model.state_dict(), path) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a2GTR-SCW3z"
      },
      "outputs": [],
      "source": [
        "input_size = 1546\n",
        "output_size = 1546\n",
        "model = Net(input_size, output_size) \n",
        "path = \"/content/drive/MyDrive/Machine_Learning_sample/NetModel2.pth\" \n",
        "model.load_state_dict(torch.load(path)) \n",
        "test_input = torch.tensor(test_input)\n",
        "test_target = torch.tensor(test_target)\n",
        "\n",
        "accuracy = 0\n",
        "for i in range(len(test_input)):\n",
        "  predict = model(test_input[i].float())\n",
        "  difference = 0\n",
        "  target = test_target[i].float()\n",
        "  for k in range(len(predict)):\n",
        "    difference += abs(predict[k] - target[k])\n",
        "  print(difference)\n",
        " \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
